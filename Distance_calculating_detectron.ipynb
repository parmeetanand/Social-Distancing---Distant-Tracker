{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from cv2_plt_imshow import cv2_plt_imshow, plt_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"video.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "cnt=0\n",
    "\n",
    "if not cap.isOpened():\n",
    "        print(\"Error opening video stream or file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,first_frame = cap.read()\n",
    "\n",
    "while(cap.isOpened()):   \n",
    "    ret, frame = cap.read()  \n",
    "    if ret == True:       \n",
    "        cv2.imwrite('frames/'+str(cnt)+'.png', frame)\n",
    "        cnt=cnt+1\n",
    "        if(cnt==200):\n",
    "              break \n",
    "    else: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/16 16:59:22 d2.modeling.backbone.resnet]: \u001b[0mResNet.make_stage(first_stride=) is deprecated!  Use 'stride_per_block' or 'stride' instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def midpoint_person(image,person,index):\n",
    "    x1,y1,x2,y2 = person[index]\n",
    "    _ = cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,0), 2)\n",
    "    \n",
    "    x_mid = int((x1+x2)/2)\n",
    "    y_mid = int(y2)\n",
    "    mid   = (x_mid,y_mid)\n",
    "\n",
    "    _ = cv2.circle(image, mid, 5, (0, 0, 255), -1)\n",
    "    cv2.putText(image, str(index), mid, cv2.FONT_HERSHEY_SIMPLEX,1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "  \n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def calculate_distance(midpoint,person):\n",
    "    dist = np.zeros((person,person))\n",
    "    for i in range(person):\n",
    "        for j in range(i+1,person):\n",
    "              if i!=j:\n",
    "                dst = distance.euclidean(midpoint[i], midpoint[j])\n",
    "                dist[i][j]=dst\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_people(dist,num_person,thres):\n",
    "    p1=[]\n",
    "    p2=[]\n",
    "    d=[]\n",
    "    for i in range(num_person):\n",
    "        for j in range(i,num_person):\n",
    "              if( (i!=j) & (dist[i][j]<=thres)):\n",
    "                p1.append(i)\n",
    "                p2.append(j)\n",
    "                d.append(dist[i][j])\n",
    "    return p1,p2,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_red(image,person,p1,p2):\n",
    "    risky = np.unique(p1+p2)\n",
    "    for i in risky:\n",
    "        x1,y1,x2,y2 = person[i]\n",
    "        _ = cv2.rectangle(image, (x1, y1), (x2, y2), (0,0,255), 2)  \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "names=os.listdir('frames/')\n",
    "names.sort(key=lambda f: int(re.sub('\\D', '', f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_distance(image_name,thres):\n",
    "\n",
    "    image = cv2.imread('frames/'+image_name)\n",
    "    outputs = predictor(image)\n",
    "    classes=outputs['instances'].pred_classes.cpu().numpy()    \n",
    "    bbox=outputs['instances'].pred_boxes.tensor.cpu().numpy()    \n",
    "    index = np.where(classes==0)[0]\n",
    "    person=bbox[index]\n",
    "    midpoints = [midpoint_person(image,person,i) for i in range(len(person))]\n",
    "    num_person = len(midpoints)\n",
    "    dist= calculate_distance(midpoints,num_person)\n",
    "    p1,p2,d= closest_people(dist,num_person,thres)\n",
    "    image = turn_red(image,person,p1,p2)\n",
    "    cv2.imwrite('frames/'+image_name,image)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres =100\n",
    "_ = [safe_distance(names[i],thres) for i in range(len(names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = os.listdir('frames/')\n",
    "frames.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "frame_array=[]\n",
    "\n",
    "for i in range(len(frames)):\n",
    "    \n",
    "    image = cv2.imread('frames/'+frames[i])\n",
    "    height, width, layers = image.shape\n",
    "    size = (width,height)\n",
    "    \n",
    "    frame_array.append(image)\n",
    "\n",
    "out = cv2.VideoWriter('safe_output.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n",
    " \n",
    "for i in range(len(frame_array)):\n",
    "    out.write(frame_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
